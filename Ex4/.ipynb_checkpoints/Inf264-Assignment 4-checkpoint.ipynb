{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Some code (such as the code to do PCA) will generate useless warnings\n",
    "# We will suppress these warning using the code below\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "Xy1 = np.genfromtxt('svmlin.csv',delimiter=',')\n",
    "X1 = Xy1[:,:2]\n",
    "y1 = Xy1[:,2]\n",
    "# Each datapoint in X is tuple of values (x0, x1). Lets plot them \n",
    "# on x and y axes respectively.\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, s=50, cmap='autumn');\n",
    "plt.xlabel(r\"$x_0$\")\n",
    "plt.ylabel(r\"$x_1$\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal distance from a hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find two lines that classify the red X as two different classes without changin the label of any of the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 3)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, s=50, cmap='autumn')\n",
    "plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# plot two lines that classify X differently\n",
    "\n",
    "for m, b in [(, ),  (, )]:\n",
    "    plt.plot(xfit, m * xfit + b, '-k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find margin for both of you lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_margin(m,b,X):\n",
    "    # TODO\n",
    "    # find the minimum margin distance to the given line\n",
    "    margins = []\n",
    "    for i in X:\n",
    "        margins.append()# calculate distance for each X\n",
    "    return np.min(margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# check the values of minimum margin for your lines\n",
    "print('margin of the first line: %.3f'%calculate_margin(1.2, 0.65,X1))\n",
    "print('margin of the second line: %.3f'%calculate_margin(-0.4, 2.9,X1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a support vector model to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "model = SVC(kernel='linear', C=1E10)\n",
    "model.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function below for ploting the SVM boundry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(X, y, model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot a black dot over the support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s = 20, facecolor= 'black');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1[:, 0], X1[:, 1], c=y1, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(X1, y1 ,model, plot_support=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy2 = np.genfromtxt('svmnonlin.csv',delimiter=',')\n",
    "X2 = Xy2[:,:2]\n",
    "y2 = Xy2[:,2]\n",
    "\n",
    "\n",
    "plt.scatter(X2[:, 0], X2[:, 1],c=y2, s=50, cmap='autumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ... # fit a linear SVM with C=1 \n",
    "...\n",
    "plt.scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(X2, y2 ,clf, plot_support=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the weighted sum of kernel values\n",
    "def compute_f(training_points , test_point, kernel, weights, gamma=1, intercept=0):\n",
    "    f = 0\n",
    "    for i in range(len(training_points)):\n",
    "        trainSample = [training_points[i]] # put the training sample into two diemnsions\n",
    "        f += ... # Complete the dual formula  (alpha*y = weights for every training sample)\n",
    "    return f + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import polynomial_kernel, rbf_kernel\n",
    "def surface_kernel(X,y,weights,clf,kernel):\n",
    "    p = np.linspace(0, 6, 10)\n",
    "    xx1, xx2 = np.meshgrid(p, p)\n",
    "\n",
    "    z = float('NaN')*np.ones(xx1.shape)\n",
    "\n",
    "    intercept = clf.intercept_\n",
    "    for i in range(z.shape[0]):\n",
    "        for j in range(z.shape[1]):\n",
    "            tst = [[xx1[i, j], xx2[i, j]]]\n",
    "            z[i, j] = compute_f(X, tst, kernel, weights, gamma=1, intercept=intercept)\n",
    "    zz = np.empty(y.shape)\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        zz[i] = compute_f(X, [X[i,:]], kernel, weights, gamma=1, intercept=intercept)\n",
    "\n",
    "    return xx1,xx2,z,zz    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twodprojection(X,model):\n",
    "\n",
    "    x_min = np.min(X[:, 0])\n",
    "    y_min = np.min(X[:, 1])\n",
    "    x_max = np.max(X[:, 0])\n",
    "    y_max = np.max(X[:, 1])\n",
    "    h = 0.01\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    return xx,yy,Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a svm with RBF kernel to the dataset: (set the kernel value to 'rbf' and gamma to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ... #Fit a SVM model with RBF kernel and gamma = 1 \n",
    "...\n",
    "weights = np.zeros((X2.shape[0], 1))\n",
    "weights[clf.support_] = clf.dual_coef_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 3D projection of the surface of dual function of SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx1, xx2, z, zz = surface_kernel(X2,y2,weights,clf,rbf_kernel)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xx1, xx2, z, alpha=0.5)\n",
    "ax.view_init(elev=45, azim=-30)\n",
    "ax.scatter(X2[:, 0], X2[:, 1], zz, s=30,c=y2,cmap='autumn')\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decision boundaries for RBF kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot decision boundary\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_light = ListedColormap(['#FFCCCC', '#80dfff'])\n",
    "xx,yy,Z = twodprojection(X2,clf)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "plt.scatter(X2[:, 0], X2[:, 1],c=y2, s=50, cmap='autumn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a svm with RBF kernel to the dataset: (set the kernel value to 'poly' and gamma to 1 and degree to 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_poly = .... # Fit a SVM with second degree polynomial kernel and gamma = 1\n",
    "....\n",
    "weights = np.zeros((X2.shape[0], 1))\n",
    "weights[clf_poly.support_] = clf_poly.dual_coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx1, xx2, z, zz = surface_kernel(X2,y2,weights,clf_poly,polynomial_kernel)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(xx1, xx2, z, alpha=0.5)\n",
    "ax.scatter(X2[:, 0], X2[:, 1], zz, s=30,c=y2,cmap='autumn')\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decision boundaries for Polynomial kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundary\n",
    "xx,yy,Z = twodprojection(X2,clf_poly)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "plt.scatter(X2[:, 0], X2[:, 1],c=y2, s=50, cmap='autumn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the SVM: Softening Margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "Xy3 = np.genfromtxt('svmmargin.csv',delimiter=',')\n",
    "X3 = Xy3[:,:2]\n",
    "y3 = Xy3[:,2]\n",
    "plt.scatter(X3[:, 0], X3[:, 1], c=y3, s=30, cmap='autumn');\n",
    "plt.xlabel(r\"$x_0$\")\n",
    "plt.ylabel(r\"$x_1$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit two different SVMs with C=10 and C=0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 8))\n",
    "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
    "\n",
    "for axi, C in zip(ax, [10.0, 0.1]):\n",
    "    model = ... # fit a linear SVM with C=C\n",
    "    axi.scatter(X3[:, 0], X3[:, 1], c=y3, s=50, cmap='autumn')\n",
    "    plot_svc_decision_function(X3,y3,model, axi)\n",
    "    axi.set_title('C = {0:.1f}'.format(C), size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the iris dataset and split it into training and test sets and perform cross validation on the training set:\n",
    "##### Hints: \n",
    "Use `train_test_split` and `cross_val_score` from `sklearn.model_selection` to split the dataset and perform cross validation for best value of $C$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "# TODO\n",
    "# Split the dataset into training and test set. (75% to 25%)\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "score_list = []\n",
    "C_list = np.arange(0.1,20,0.05)\n",
    "# TODO\n",
    "# perform cross validation on the training set \n",
    "for C in C_list: \n",
    "    clf = ....\n",
    "    score = ....\n",
    "    score_list.append(score.mean())\n",
    "best_C = C_list[np.argmax(score_list)]\n",
    "print('The best value for C is :%.3f'%best_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy score on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "clf = ...\n",
    "...\n",
    "print(accuracy_score(,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the implementation of phi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    # TODO\n",
    "    # Complete the implementation\n",
    "    transformed_x = np.empty(0)\n",
    "    for i in range(...):\n",
    "        transformed_x = np.concatenate((transformed_x,...))# Power of two terms\n",
    "    for i in range(...):\n",
    "        for j in range(...):\n",
    "            if (i!=j):\n",
    "                transformed_x = np.concatenate((transformed_x,...)) # Multipilication Terms\n",
    "    for i in range(...):\n",
    "        transformed_x = np.concatenate((transformed_x,...)) #single Terms\n",
    "    transformed_x = np.concatenate((transformed_x,[1]))\n",
    "    return transformed_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the run time in normal way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "np.random.seed(3)\n",
    "run_time = []\n",
    "kernel_values = []\n",
    "for d in range(1,500,100):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    x = np.random.uniform(0,100,[d,1])\n",
    "    z = np.random.uniform(0,100,[d,1])\n",
    "    x_k = phi(x)\n",
    "    z_k = phi(z)\n",
    "    kernel_values.append(...) # the value of K(x,z) using phi\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    run_time.append(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the run time for Kernel Trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "run_time_trick = []\n",
    "kernel_values_trick = []\n",
    "for d in range(1,500,100):\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    x = np.random.uniform(0,100,[d,1])\n",
    "    z = np.random.uniform(0,100,[d,1])\n",
    "    # TODO\n",
    "    kernel_values_trick.append((...) # the value of K(x,z) using kernel trick \n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    run_time_trick.append(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the run times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,500,100),run_time,'R',label='run time for high dimensional computation')\n",
    "plt.plot(range(1,500,100),run_time_trick,'B',label='run time for kernel trick')\n",
    "plt.grid()\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('run time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the values of the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_values_trick"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
